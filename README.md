# ğŸ§¬ Histone-Based Gene Expression Prediction

This project applies deep learning to predict gene expression levels from histone modification signals using Transformer-based architectures.

## ğŸ“ Dataset

- Input: Histone mark signals (3 Ã— 100 window)
- Output: Normalized gene expression
- Preprocessed into train/val/test splits

## ğŸ§  Model Architecture

- Residual CNN for signal feature extraction
- Transformer Encoder with 10 layers
- Multi-head Attention Pooling (4 heads)
- Regressor with LayerNorm and Dropout
- Positional encoding included
- **Loss**: Combined MSE and Pearson correlation
- **Optimizer**: Adam + weight decay + LR scheduler
- **Early stopping**: Enabled

## ğŸŒ± Ensemble Strategy

- Trained 5 models with different seeds
- Averaged predictions for robust generalization

## ğŸ“Š Evaluation Metrics

| Metric        | Validation | Test   |
|---------------|------------|--------|
| Pearson R     | ~0.80      | **0.8050** |
| Spearman R    | ~0.80      | **0.8051** |
| RÂ² Score      | â€”          | **0.6469** |

## ğŸ“ˆ Visualizations

- âœ… Ensemble prediction vs. ground truth scatter plot
- â³ Training & validation loss tracking (optional)
- ğŸ“‰ Performance comparisons

## ğŸ“ Files

- `model_seed*.pt`: model checkpoints (not uploaded)
- `ensemble_predictions.csv`: test inputs, labels, predictions
- `scatter_plot.png`: ensemble visualization
- `README.md`: project overview

## ğŸ’¡ Future Work

- Add training/validation loss curves
- Experiment with alternative input representations
- Try larger models or unfreezing pretrained encoders

---

If you use this project or find it helpful, feel free to â­ï¸ the repo or cite it in your own work.
